{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [4]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2520\\157719567.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mpadding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkernel_size\u001B[0m \u001B[1;33m//\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mkernel_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkernel_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mpadding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpadding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\PyUnion\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PyUnion\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 313\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    314\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PyUnion\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    307\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    308\u001B[0m                             _single(0), self.dilation, self.groups)\n\u001B[1;32m--> 309\u001B[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001B[0m\u001B[0;32m    310\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    311\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [4]"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = 1\n",
    "gamma = 2\n",
    "kernel_size = int(abs((math.log(a.size(0), 2) + b) / gamma))\n",
    "kernel_size = kernel_size if kernel_size % 2 else kernel_size + 1\n",
    "padding = kernel_size // 2\n",
    "conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "print(conv(a))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.7303,  0.4111, -0.8765,  ..., -0.7420, -0.0500,  1.1582],\n         [ 0.9338,  0.0523,  0.1893,  ...,  0.8889,  0.4643,  0.5163],\n         [-0.5467, -0.1185,  0.4334,  ...,  0.0898, -0.1525,  0.9678],\n         ...,\n         [ 0.2033, -0.5721, -0.2326,  ...,  0.8604,  0.3447,  0.2343],\n         [ 0.9602,  0.2432,  1.2249,  ...,  1.5224, -0.3048,  0.2947],\n         [ 0.5236,  0.1278, -0.2121,  ...,  0.3347, -0.3923,  0.0469]],\n\n        [[ 0.6709,  0.6339,  0.1473,  ...,  0.1689,  0.5694,  0.2112],\n         [ 1.0376,  1.4972, -0.2753,  ...,  0.0321,  0.2865,  0.9762],\n         [-0.5480,  0.2863,  0.0902,  ..., -0.7054, -0.6745, -1.0389],\n         ...,\n         [-0.1031,  0.0276, -0.4857,  ..., -0.3334, -0.8391, -0.5934],\n         [-0.8177, -0.0915, -0.3736,  ..., -0.2985, -0.3014, -0.6626],\n         [-0.8721,  0.0446, -1.2738,  ..., -0.1998, -0.3159, -0.1962]],\n\n        [[-0.5534, -0.4166, -0.9847,  ...,  0.6085,  1.0226, -0.1691],\n         [-0.6020,  0.2341, -0.9030,  ..., -0.4709, -0.0762,  0.7641],\n         [ 0.1763,  0.1825, -0.1497,  ...,  1.2431,  0.4171, -0.6388],\n         ...,\n         [ 0.5222,  0.1923,  0.2265,  ...,  0.7944,  0.1731, -0.2212],\n         [-0.4685, -0.3844,  0.3258,  ..., -0.6970, -0.2827,  0.3804],\n         [-0.1762,  0.9487, -0.4908,  ..., -0.4734, -0.1020,  0.7028]],\n\n        ...,\n\n        [[-0.3507,  0.0784, -0.0869,  ...,  0.9312,  0.2019,  0.0580],\n         [ 0.1171,  0.7073, -0.2785,  ...,  0.5525,  0.1377, -0.5374],\n         [ 0.2636, -0.1864, -0.1155,  ..., -0.6095, -0.8017, -0.7784],\n         ...,\n         [-0.3837, -0.2648, -0.5225,  ..., -0.1696, -0.7802, -0.0231],\n         [ 0.7059,  0.1814,  0.0044,  ...,  0.6016, -0.8060,  0.1553],\n         [ 0.2293,  0.0324, -0.0831,  ...,  0.5041,  0.3690,  0.5287]],\n\n        [[ 0.7029,  0.2355, -0.1788,  ...,  0.4659, -0.3792,  0.4527],\n         [-0.6114,  0.7099, -0.2656,  ...,  1.0934,  0.0412,  0.2590],\n         [ 0.3521, -0.3370, -0.2575,  ...,  0.1811, -0.1753,  0.2276],\n         ...,\n         [-1.5185,  0.1976, -1.0078,  ...,  0.6785,  0.8215, -0.4322],\n         [ 0.2336, -0.6379,  0.4125,  ..., -0.8174,  0.4253, -0.0037],\n         [-1.0586, -0.1067, -0.3936,  ...,  0.0620,  0.3103, -1.1348]],\n\n        [[-0.4704, -0.5321, -0.4424,  ...,  0.0504,  1.0559, -0.9393],\n         [-1.5216,  0.5785, -0.7544,  ...,  0.0470, -0.3506, -0.2664],\n         [ 0.6928,  0.3164, -0.6314,  ...,  0.4987,  0.1430, -1.2083],\n         ...,\n         [-0.7226,  0.2432,  0.6406,  ..., -0.4034, -0.4185, -0.1805],\n         [ 0.3223, -0.6385, -0.4437,  ..., -0.5244, -1.1313,  0.7533],\n         [-0.0229,  0.3551, -0.9667,  ...,  0.0955, -0.2468, -0.1974]]],\n       grad_fn=<ConvolutionBackward0>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "ip = torch.randn(20, 16, 50)\n",
    "op = m(ip)\n",
    "op"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
